{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #2\n",
    "Develop a Baseline Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -40.02 (18.46) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #3\n",
    "Modeling The Standardized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -24.82 (26.52) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension Of Step #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = utils.to_categorical(encoded_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(1 , activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -546.51 (276.41) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #4\n",
    "Tune The Neural Network Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #4.1\n",
    "Evaluate a Deeper Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(6 , activation='relu' , ))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.91 (20.99) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #4.2\n",
    "Evaluate a Wider Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(20 , activation='relu' , ))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -23.86 (26.50) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #5\n",
    "Really Scaling up: developing a model that overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(20 , activation='relu' ,))\n",
    "    model.add(layers.Dense(25 , activation='relu' ,))\n",
    "    model.add(layers.Dense(25 , activation='relu' ,))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standerized: -22.25 (25.09) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standerized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(13 , activation='relu' , input_shape=(13,)))\n",
    "    model.add(layers.Dense(1 , ))\n",
    "    \n",
    "    model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standerized: -27.22 (24.63) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standerized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tensorflow.keras.Input(shape=(13,))\n",
    "x = layers.Dense(13 , activation='relu')(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "model = tensorflow.keras.Model(inputs , outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 506 samples\n",
      "Epoch 1/50\n",
      "506/506 [==============================] - 3s 7ms/sample - loss: 548.3365 - mae: 17.5990\n",
      "Epoch 2/50\n",
      "506/506 [==============================] - 0s 514us/sample - loss: 265.8300 - mae: 11.3353\n",
      "Epoch 3/50\n",
      "506/506 [==============================] - 0s 504us/sample - loss: 192.9207 - mae: 9.7302\n",
      "Epoch 4/50\n",
      "506/506 [==============================] - 0s 519us/sample - loss: 150.3639 - mae: 8.4219\n",
      "Epoch 5/50\n",
      "506/506 [==============================] - 0s 514us/sample - loss: 123.6716 - mae: 7.6805\n",
      "Epoch 6/50\n",
      "506/506 [==============================] - 0s 519us/sample - loss: 102.3723 - mae: 7.1114\n",
      "Epoch 7/50\n",
      "506/506 [==============================] - 0s 321us/sample - loss: 90.0447 - mae: 6.7436\n",
      "Epoch 8/50\n",
      "506/506 [==============================] - 0s 379us/sample - loss: 79.9444 - mae: 6.4015\n",
      "Epoch 9/50\n",
      "506/506 [==============================] - 0s 324us/sample - loss: 70.4884 - mae: 6.1770\n",
      "Epoch 10/50\n",
      "506/506 [==============================] - 0s 690us/sample - loss: 61.1260 - mae: 5.5745\n",
      "Epoch 11/50\n",
      "506/506 [==============================] - 0s 861us/sample - loss: 54.8240 - mae: 5.2772\n",
      "Epoch 12/50\n",
      "506/506 [==============================] - 0s 340us/sample - loss: 52.5546 - mae: 5.1122\n",
      "Epoch 13/50\n",
      "506/506 [==============================] - 0s 332us/sample - loss: 50.2164 - mae: 5.1254\n",
      "Epoch 14/50\n",
      "506/506 [==============================] - 0s 379us/sample - loss: 47.9254 - mae: 4.9574\n",
      "Epoch 15/50\n",
      "506/506 [==============================] - 0s 358us/sample - loss: 46.1823 - mae: 4.7570\n",
      "Epoch 16/50\n",
      "506/506 [==============================] - 0s 330us/sample - loss: 42.0865 - mae: 4.6397\n",
      "Epoch 17/50\n",
      "506/506 [==============================] - 0s 355us/sample - loss: 41.6293 - mae: 4.5445\n",
      "Epoch 18/50\n",
      "506/506 [==============================] - 0s 348us/sample - loss: 43.0475 - mae: 4.8821\n",
      "Epoch 19/50\n",
      "506/506 [==============================] - 0s 339us/sample - loss: 42.2500 - mae: 4.6719\n",
      "Epoch 20/50\n",
      "506/506 [==============================] - 0s 334us/sample - loss: 38.6432 - mae: 4.3987\n",
      "Epoch 21/50\n",
      "506/506 [==============================] - 0s 334us/sample - loss: 38.4937 - mae: 4.4395\n",
      "Epoch 22/50\n",
      "506/506 [==============================] - 0s 340us/sample - loss: 38.9486 - mae: 4.5277\n",
      "Epoch 23/50\n",
      "506/506 [==============================] - 0s 324us/sample - loss: 36.1095 - mae: 4.3125\n",
      "Epoch 24/50\n",
      "506/506 [==============================] - 0s 346us/sample - loss: 35.7873 - mae: 4.3135\n",
      "Epoch 25/50\n",
      "506/506 [==============================] - 0s 331us/sample - loss: 37.6972 - mae: 4.5195\n",
      "Epoch 26/50\n",
      "506/506 [==============================] - 0s 339us/sample - loss: 35.3451 - mae: 4.3180\n",
      "Epoch 27/50\n",
      "506/506 [==============================] - 0s 339us/sample - loss: 34.4503 - mae: 4.3099\n",
      "Epoch 28/50\n",
      "506/506 [==============================] - 0s 355us/sample - loss: 35.0350 - mae: 4.2941\n",
      "Epoch 29/50\n",
      "506/506 [==============================] - 0s 339us/sample - loss: 34.4665 - mae: 4.2637\n",
      "Epoch 30/50\n",
      "506/506 [==============================] - 0s 350us/sample - loss: 35.9125 - mae: 4.4097\n",
      "Epoch 31/50\n",
      "506/506 [==============================] - 0s 322us/sample - loss: 33.1948 - mae: 4.1194\n",
      "Epoch 32/50\n",
      "506/506 [==============================] - 0s 343us/sample - loss: 32.5830 - mae: 4.1520\n",
      "Epoch 33/50\n",
      "506/506 [==============================] - 0s 360us/sample - loss: 34.1016 - mae: 4.2696\n",
      "Epoch 34/50\n",
      "506/506 [==============================] - 0s 337us/sample - loss: 33.4503 - mae: 4.2552\n",
      "Epoch 35/50\n",
      "506/506 [==============================] - 0s 336us/sample - loss: 32.2150 - mae: 4.1771\n",
      "Epoch 36/50\n",
      "506/506 [==============================] - 0s 332us/sample - loss: 32.9698 - mae: 4.2253\n",
      "Epoch 37/50\n",
      "506/506 [==============================] - 0s 348us/sample - loss: 32.3136 - mae: 4.0367\n",
      "Epoch 38/50\n",
      "506/506 [==============================] - 0s 348us/sample - loss: 31.7006 - mae: 4.0962\n",
      "Epoch 39/50\n",
      "506/506 [==============================] - 0s 327us/sample - loss: 31.5471 - mae: 4.1220\n",
      "Epoch 40/50\n",
      "506/506 [==============================] - 0s 342us/sample - loss: 31.7240 - mae: 4.0689\n",
      "Epoch 41/50\n",
      "506/506 [==============================] - 0s 351us/sample - loss: 32.1457 - mae: 4.1329\n",
      "Epoch 42/50\n",
      "506/506 [==============================] - 0s 346us/sample - loss: 34.1343 - mae: 4.3000\n",
      "Epoch 43/50\n",
      "506/506 [==============================] - 0s 338us/sample - loss: 33.9112 - mae: 4.2817\n",
      "Epoch 44/50\n",
      "506/506 [==============================] - 0s 335us/sample - loss: 31.1899 - mae: 4.0718\n",
      "Epoch 45/50\n",
      "506/506 [==============================] - 0s 340us/sample - loss: 31.9230 - mae: 4.1482\n",
      "Epoch 46/50\n",
      "506/506 [==============================] - 0s 341us/sample - loss: 31.3623 - mae: 4.0752\n",
      "Epoch 47/50\n",
      "506/506 [==============================] - 0s 333us/sample - loss: 31.4382 - mae: 4.0977\n",
      "Epoch 48/50\n",
      "506/506 [==============================] - 0s 339us/sample - loss: 30.3060 - mae: 3.9875\n",
      "Epoch 49/50\n",
      "506/506 [==============================] - 0s 337us/sample - loss: 30.9487 - mae: 4.0844\n",
      "Epoch 50/50\n",
      "506/506 [==============================] - 0s 349us/sample - loss: 31.5684 - mae: 4.1015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1faf7857988>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam' , loss='mse' , metrics=['mae'])\n",
    "model.fit(X , Y , epochs=50 , batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tensorflow.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1=layers.Dense(13 , activation='relu')\n",
    "        self.dense2=layers.Dense(1 ,)\n",
    "        \n",
    "    def call(self , inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "model=MyModel()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 506 samples\n",
      "Epoch 1/50\n",
      "506/506 [==============================] - 1s 1ms/sample - loss: 36.6358\n",
      "Epoch 2/50\n",
      "506/506 [==============================] - 0s 289us/sample - loss: 36.0646\n",
      "Epoch 3/50\n",
      "506/506 [==============================] - 0s 297us/sample - loss: 36.8429\n",
      "Epoch 4/50\n",
      "506/506 [==============================] - 0s 298us/sample - loss: 35.1077\n",
      "Epoch 5/50\n",
      "506/506 [==============================] - 0s 294us/sample - loss: 35.1713\n",
      "Epoch 6/50\n",
      "506/506 [==============================] - 0s 298us/sample - loss: 35.9956\n",
      "Epoch 7/50\n",
      "506/506 [==============================] - 0s 346us/sample - loss: 36.7591\n",
      "Epoch 8/50\n",
      "506/506 [==============================] - 0s 304us/sample - loss: 33.7134\n",
      "Epoch 9/50\n",
      "506/506 [==============================] - 0s 302us/sample - loss: 33.8468\n",
      "Epoch 10/50\n",
      "506/506 [==============================] - 0s 298us/sample - loss: 34.6597\n",
      "Epoch 11/50\n",
      "506/506 [==============================] - 0s 290us/sample - loss: 37.7274\n",
      "Epoch 12/50\n",
      "506/506 [==============================] - 0s 290us/sample - loss: 33.9848\n",
      "Epoch 13/50\n",
      "506/506 [==============================] - 0s 296us/sample - loss: 35.6866\n",
      "Epoch 14/50\n",
      "506/506 [==============================] - 0s 294us/sample - loss: 35.2094\n",
      "Epoch 15/50\n",
      "506/506 [==============================] - 0s 298us/sample - loss: 33.9295\n",
      "Epoch 16/50\n",
      "506/506 [==============================] - 0s 306us/sample - loss: 33.1538\n",
      "Epoch 17/50\n",
      "506/506 [==============================] - 0s 314us/sample - loss: 36.8063\n",
      "Epoch 18/50\n",
      "506/506 [==============================] - 0s 336us/sample - loss: 35.1230\n",
      "Epoch 19/50\n",
      "506/506 [==============================] - 0s 308us/sample - loss: 33.3876\n",
      "Epoch 20/50\n",
      "506/506 [==============================] - 0s 324us/sample - loss: 35.6173\n",
      "Epoch 21/50\n",
      "506/506 [==============================] - 0s 320us/sample - loss: 33.4921\n",
      "Epoch 22/50\n",
      "506/506 [==============================] - 0s 318us/sample - loss: 35.1070\n",
      "Epoch 23/50\n",
      "506/506 [==============================] - 0s 290us/sample - loss: 32.1002\n",
      "Epoch 24/50\n",
      "506/506 [==============================] - 0s 312us/sample - loss: 32.9687\n",
      "Epoch 25/50\n",
      "506/506 [==============================] - 0s 312us/sample - loss: 31.2093\n",
      "Epoch 26/50\n",
      "506/506 [==============================] - 0s 294us/sample - loss: 35.0781\n",
      "Epoch 27/50\n",
      "506/506 [==============================] - 0s 290us/sample - loss: 32.4039\n",
      "Epoch 28/50\n",
      "506/506 [==============================] - 0s 306us/sample - loss: 33.8159\n",
      "Epoch 29/50\n",
      "506/506 [==============================] - 0s 290us/sample - loss: 31.1149\n",
      "Epoch 30/50\n",
      "506/506 [==============================] - 0s 300us/sample - loss: 31.9073\n",
      "Epoch 31/50\n",
      "506/506 [==============================] - 0s 286us/sample - loss: 31.5327\n",
      "Epoch 32/50\n",
      "506/506 [==============================] - 0s 307us/sample - loss: 30.7973\n",
      "Epoch 33/50\n",
      "506/506 [==============================] - 0s 312us/sample - loss: 30.6340\n",
      "Epoch 34/50\n",
      "506/506 [==============================] - 0s 288us/sample - loss: 35.7656\n",
      "Epoch 35/50\n",
      "506/506 [==============================] - 0s 300us/sample - loss: 29.9931\n",
      "Epoch 36/50\n",
      "506/506 [==============================] - 0s 332us/sample - loss: 30.5217\n",
      "Epoch 37/50\n",
      "506/506 [==============================] - 0s 310us/sample - loss: 31.4774\n",
      "Epoch 38/50\n",
      "506/506 [==============================] - 0s 286us/sample - loss: 34.7234\n",
      "Epoch 39/50\n",
      "506/506 [==============================] - 0s 308us/sample - loss: 30.0715\n",
      "Epoch 40/50\n",
      "506/506 [==============================] - 0s 320us/sample - loss: 30.0003\n",
      "Epoch 41/50\n",
      "506/506 [==============================] - 0s 330us/sample - loss: 32.8967\n",
      "Epoch 42/50\n",
      "506/506 [==============================] - 0s 318us/sample - loss: 28.7778\n",
      "Epoch 43/50\n",
      "506/506 [==============================] - 0s 284us/sample - loss: 33.5848\n",
      "Epoch 44/50\n",
      "506/506 [==============================] - 0s 296us/sample - loss: 30.1853\n",
      "Epoch 45/50\n",
      "506/506 [==============================] - 0s 296us/sample - loss: 33.4309\n",
      "Epoch 46/50\n",
      "506/506 [==============================] - 0s 338us/sample - loss: 28.9619\n",
      "Epoch 47/50\n",
      "506/506 [==============================] - 0s 308us/sample - loss: 29.1521\n",
      "Epoch 48/50\n",
      "506/506 [==============================] - 0s 306us/sample - loss: 32.5722\n",
      "Epoch 49/50\n",
      "506/506 [==============================] - 0s 294us/sample - loss: 32.3294\n",
      "Epoch 50/50\n",
      "506/506 [==============================] - 0s 298us/sample - loss: 28.5526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x153fc5454c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer ='Adam' , loss= 'mse' , accuracy=['mae'])\n",
    "model.fit(X , Y , epochs = 50 , batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
